import streamlit as st
import pandas as pd
import joblib
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# --- VARI√ÅVEIS GLOBAIS (FEATURES) ---
FEATURES_LIST = [
    'Industry',
    'Required Education',
    'Median Salary (USD)',
    'Experience Required (Years)',
    'Remote Work Ratio (%)'
]

NUMERIC_FEATURES = [
    'Median Salary (USD)',
    'Experience Required (Years)',
    'Remote Work Ratio (%)'
]

CATEGORICAL_FEATURES = [
    'Industry',
    'Required Education'
]

# --- 1. CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="Previsor de Impacto da IA",
    page_icon="ü§ñ",
    layout="wide"
)

# --- 2. FUN√á√ïES DE CARREGAMENTO (COM CACHE) ---

@st.cache_resource
def load_model(path="ai_impact_model.joblib"):
    """Carrega o pipeline de modelo .joblib."""
    if not os.path.exists(path):
        st.error(f"‚ùå Erro: Arquivo do modelo '{path}' n√£o encontrado!")
        st.stop()
    try:
        model = joblib.load(path)
        return model
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar o modelo: {str(e)}")
        st.stop()

@st.cache_data
def load_data(path="ai_job_trends_dataset.csv"):
    """Carrega o dataset CSV completo para a aba EDA."""
    if not os.path.exists(path):
        st.error(f"‚ùå Erro: Arquivo de dados '{path}' n√£o encontrado para a Aba 'An√°lise'!")
        st.stop()
    try:
        df = pd.read_csv(path)
        return df
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar os dados: {str(e)}")
        st.stop()

# --- 3. CARREGAMENTO DOS DADOS E MODELO ---
model = load_model()
df = load_data()

# --- 4. SIDEBAR COM INPUTS DO USU√ÅRIO ---
st.sidebar.header("üìä Par√¢metros da Profiss√£o")
st.sidebar.markdown("Preencha os campos para a previs√£o:")

# Inputs da Sidebar
industry = st.sidebar.selectbox(
    "Industry (Ind√∫stria)",
    options=df['Industry'].unique(), # Pega op√ß√µes direto do DF
    index=0
)

education = st.sidebar.selectbox(
    "Required Education (Educa√ß√£o)",
    options=df['Required Education'].unique(), # Pega op√ß√µes direto do DF
    index=0
)

salary = st.sidebar.number_input(
    "Median Salary (USD) (Sal√°rio)",
    min_value=30000,
    max_value=150000,
    value=90000, # Valor padr√£o (m√©dia)
    step=1000,
    format="%d"
)

experience = st.sidebar.slider(
    "Experience Required (Years) (Experi√™ncia)",
    min_value=0,
    max_value=40,
    value=10, # Valor padr√£o (m√©dia)
    step=1
)

remote_work = st.sidebar.slider(
    "Remote Work Ratio (%) (Trabalho Remoto)",
    min_value=0,
    max_value=100,
    value=50, # Valor padr√£o (m√©dia)
    step=1
)

predict_button = st.sidebar.button("üîÆ Prever Impacto", type="primary", use_container_width=True)

# --- 5. ESTRUTURA DAS ABAS ---
st.title("ü§ñ Previsor de Impacto da IA no Trabalho")

tab1, tab2, tab3 = st.tabs([
    "**Previsor Interativo**",
    "**Sobre o Modelo (Valida√ß√£o)**",
    "**O Padr√£o nos Dados**"
])


# --- ABA 1: PREVISOR ---
with tab1:
    st.header("Previs√£o de Impacto da IA")
    
    if predict_button:
        try:
            # 1. Criar o dicion√°rio de dados usando as features globais
            input_data = {
                'Industry': [industry],
                'Required Education': [education],
                'Median Salary (USD)': [salary],
                'Experience Required (Years)': [experience],
                'Remote Work Ratio (%)': [remote_work]
            }
            
            # 2. Criar o DataFrame FOR√áANDO a ordem das colunas (usando FEATURES_LIST)
            input_df = pd.DataFrame(input_data, columns=FEATURES_LIST)

            # 4. Fazer a previs√£o de PROBABILIDADE
            probabilities = model.predict_proba(input_df)[0]
            prediction = model.predict(input_df)[0]
            
            # 5. Criar DataFrame para o gr√°fico de confian√ßa
            prob_df = pd.DataFrame({
                'N√≠vel de Risco': model.classes_,
                'Confian√ßa (%)': probabilities * 100
            }).sort_values(by='Confian√ßa (%)', ascending=False)
            
            
            # 6. Exibir o resultado
            st.subheader("üìà Resultado da Previs√£o")
            
            if prediction == "Low":
                st.success("üü¢ **Impacto Baixo**")
            elif prediction == "Moderate":
                st.warning("üü° **Impacto Moderado**")
            elif prediction == "High":
                st.error("üî¥ **Impacto Alto**")

            # 7. O Gr√°fico "UAU" (Confian√ßa)
            st.subheader(f"N√≠vel de Confian√ßa da Previs√£o: {probabilities.max()*100:.1f}%")
            st.bar_chart(prob_df.set_index('N√≠vel de Risco'))
            
            st.markdown("---")
            st.subheader("üìã Par√¢metros Utilizados")
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Ind√∫stria:** {industry}")
                st.write(f"**Educa√ß√£o:** {education}")
            with col2:
                st.write(f"**Sal√°rio M√©dio:** ${salary:,.0f}")
                st.write(f"**Experi√™ncia:** {experience} anos")
                st.write(f"**Trabalho Remoto:** {remote_work}%")
                
        except Exception as e:
            st.error(f"‚ùå Erro ao fazer a previs√£o: {str(e)}")

    else:
        st.info("üëà **Preencha os par√¢metros na barra lateral e clique em 'Prever Impacto' para obter uma an√°lise.**")
        
        st.markdown("---")
        st.subheader("üß™ Desafio: Teste Sua Intui√ß√£o!")
        st.warning(
            "**Voc√™ consegue desafiar o modelo?** A IA descobriu padr√µes surpreendentes nos dados. "
            "Tente preencher os campos acima e veja se consegue encontrar uma combina√ß√£o que "
            "contradiga os padr√µes identificados na aba **'O Padr√£o nos Dados'**!"
        )


# --- ABA 2: SOBRE O MODELO (VALIDA√á√ÉO) ---
with tab2:
    st.header("Valida√ß√£o e Performance do Modelo")
    
    st.subheader("Performance (Acur√°cia de 96%)")
    st.write("O modelo foi treinado com 24.000 amostras e validado em 6.000 amostras novas (dados que ele nunca viu), atingindo 96% de acur√°cia.")
    
    # Matriz de Confus√£o - Gera√ß√£o Din√¢mica
    st.subheader("Matriz de Confus√£o")
    if os.path.exists("matriz_de_confusao.png"):
        st.image("matriz_de_confusao.png",
                 caption="Matriz de Confus√£o (Valida√ß√£o em 6.000 amostras de teste)",
                 width=600)
    else:
        # Gera matriz de confus√£o dinamicamente usando uma amostra do dataset
        try:
            # Usa as features globais definidas
            feature_columns = FEATURES_LIST
            
            # Usa uma amostra representativa do dataset para demonstrar
            # (em produ√ß√£o, voc√™ usaria o conjunto de teste real)
            sample_size = min(6000, len(df))
            sample_df = df.sample(n=sample_size, random_state=42)
            X_sample = sample_df[feature_columns]
            y_sample = sample_df['AI Impact Level']
            
            # Faz predi√ß√µes
            y_pred_sample = model.predict(X_sample)
            
            # Cria a matriz de confus√£o
            labels = ['Low', 'Moderate', 'High']
            cm = confusion_matrix(y_sample, y_pred_sample, labels=labels)
            
            # Calcula m√©tricas adicionais
            from sklearn.metrics import accuracy_score, classification_report
            accuracy = accuracy_score(y_sample, y_pred_sample)
            
            # Plota a matriz de confus√£o
            fig_cm, ax_cm = plt.subplots(figsize=(10, 8))
            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
            disp.plot(ax=ax_cm, cmap='Blues', values_format='d')
            title = (
                f'Matriz de Confus√£o (Amostra de {sample_size:,} registros)\n'
                f'Acur√°cia: {accuracy*100:.2f}%'
            )
            ax_cm.set_title(title, fontsize=12, fontweight='bold')
            plt.tight_layout()
            st.pyplot(fig_cm)
            
            # Mostra m√©tricas detalhadas
            with st.expander("üìä Ver M√©tricas Detalhadas de Classifica√ß√£o"):
                report = classification_report(y_sample, y_pred_sample, labels=labels, output_dict=True)
                report_df = pd.DataFrame(report).transpose()
                st.dataframe(report_df, use_container_width=True)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Acur√°cia Geral", f"{accuracy*100:.2f}%")
                with col2:
                    st.metric("Precis√£o M√©dia", f"{report_df.loc['macro avg', 'precision']*100:.2f}%")
                with col3:
                    st.metric("Recall M√©dio", f"{report_df.loc['macro avg', 'recall']*100:.2f}%")
            
            st.caption(
                "‚ö†Ô∏è **Nota:** Esta matriz foi gerada com uma amostra do dataset "
                "completo. A valida√ß√£o real do modelo foi realizada com 6.000 "
                "amostras separadas do conjunto de treinamento, atingindo "
                "96% de acur√°cia."
            )
            
        except Exception as e:
            st.error(f"Erro ao gerar matriz de confus√£o: {e}")
            st.info("üí° Dica: Para gerar a matriz de confus√£o real, execute o c√≥digo de valida√ß√£o no seu notebook e salve como 'matriz_de_confusao.png'.")

    st.markdown("---")
    st.subheader("Validando a Alta Acur√°cia")
    st.write(
        "O modelo RandomForestClassifier foi validado com m√©tricas rigorosas. "
        "Abaixo, voc√™ pode ver quais fatores o modelo mais utiliza para tomar decis√µes."
    )
    st.markdown("---")
    st.subheader("O que √© mais importante para o Modelo? (Feature Importance)")
    st.write("O gr√°fico abaixo mostra quais fatores o modelo mais usou para tomar a decis√£o:")
    
    try:
        # Pega o classificador do pipeline
        classifier = model.named_steps['classifier']
        
        # Verifica se o classificador tem feature_importances_
        if hasattr(classifier, 'feature_importances_'):
            # Pega o preprocessor
            preprocessor = model.named_steps['preprocessor']
            
            # Usa as features globais definidas
            feature_columns = FEATURES_LIST
            cat_features = CATEGORICAL_FEATURES
            num_features = NUMERIC_FEATURES
            
            # Obt√©m os nomes das features ap√≥s o OneHotEncoder
            try:
                onehot = preprocessor.named_transformers_['cat'].named_steps['onehot']
                # Usa as features categ√≥ricas globais
                cat_transformed_names = onehot.get_feature_names_out(cat_features)
            except Exception:
                # Fallback: cria nomes manualmente baseado nos valores √∫nicos
                cat_transformed_names = []
                for col in cat_features:
                    unique_vals = sorted(df[col].unique())
                    for val in unique_vals:
                        cat_transformed_names.append(f"{col}_{val}")
            
            # Combina todas as features na ordem correta (num√©ricas primeiro, depois categ√≥ricas)
            all_features_names = num_features + list(cat_transformed_names)
            
            # Verifica se o n√∫mero de features corresponde
            n_expected = len(classifier.feature_importances_)
            n_obtained = len(all_features_names)
            if n_expected != n_obtained:
                st.warning(
                    f"‚ö†Ô∏è N√∫mero de features n√£o corresponde. "
                    f"Esperado: {n_expected}, Obtido: {n_obtained}"
                )
                # Usa apenas as primeiras N features
                all_features_names = all_features_names[:n_expected]
            
            # Cria dataframe de import√¢ncia
            importance_df = pd.DataFrame({
                'Feature': all_features_names,
                'Import√¢ncia': classifier.feature_importances_
            }).sort_values(by='Import√¢ncia', ascending=False)
            
            # Limpa nomes para melhor visualiza√ß√£o (ex: "Industry_IT" -> "Industry: IT")
            importance_df['Feature'] = importance_df['Feature'].str.replace("_", ": ", n=1)
            
            # Plota o gr√°fico de import√¢ncia horizontalmente (Top 10)
            # Usa Matplotlib/Seaborn para controle total de tamanho e orienta√ß√£o
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # Usa Seaborn para plotar HORIZONTALMENTE (y=Feature, x=Import√¢ncia)
            sns.barplot(
                data=importance_df.head(10),
                y='Feature',
                x='Import√¢ncia',
                color='#1f77b4'  # Cor padr√£o do Streamlit para manter consist√™ncia
            )
            plt.title('Top 10 Fatores Mais Importantes', fontsize=14, fontweight='bold')
            plt.xlabel('Import√¢ncia Relativa', fontsize=12)
            plt.ylabel('')  # Remove o label do eixo Y para mais espa√ßo
            plt.tight_layout()
            
            st.pyplot(fig)
            
            # Mostra estat√≠sticas
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Feature Mais Importante", importance_df.iloc[0]['Feature'])
            with col2:
                st.metric("Import√¢ncia", f"{importance_df.iloc[0]['Import√¢ncia']*100:.2f}%")
            
            with st.expander("üìã Ver todas as features e suas import√¢ncias"):
                st.dataframe(importance_df, use_container_width=True)
                
        else:
            st.warning(
                "‚ö†Ô∏è Este modelo n√£o possui feature_importances_ "
                "(pode n√£o ser um RandomForest ou outro modelo baseado em "
                "√°rvores)."
            )

    except Exception as e:
        st.error(f"Erro ao calcular feature importance: {e}")
        st.info(
            "üí° Dica: Verifique se o modelo foi treinado com "
            "RandomForestClassifier ou outro modelo que tenha "
            "feature_importances_."
        )

# --- ABA 3: O PADR√ÉO NOS DADOS ---
with tab3:
    st.header("üìä O Padr√£o nos Dados")
    st.write("An√°lise comparativa dos padr√µes aprendidos pelo modelo: **Alto Risco vs. Baixo Risco**")
    
    # Calcula m√©dias para Low e High usando filtro direto (mais confi√°vel)
    df_low = df[df['AI Impact Level'] == 'Low'].copy()
    df_high = df[df['AI Impact Level'] == 'High'].copy()
    
    # Valida√ß√£o: verifica se os filtros funcionaram
    if len(df_low) == 0 or len(df_high) == 0:
        st.error("‚ùå Erro: N√£o foi poss√≠vel filtrar os dados por n√≠vel de risco.")
        st.info(f"Valores √∫nicos encontrados: {df['AI Impact Level'].unique()}")
    else:
        avg_low_salary = df_low['Median Salary (USD)'].mean()
        avg_high_salary = df_high['Median Salary (USD)'].mean()
        
        avg_low_experience = df_low['Experience Required (Years)'].mean()
        avg_high_experience = df_high['Experience Required (Years)'].mean()
        
        avg_low_remote = df_low['Remote Work Ratio (%)'].mean()
        avg_high_remote = df_high['Remote Work Ratio (%)'].mean()
    
        st.markdown("---")
        
        # Nota Cr√≠tica (substitui a tabela de compara√ß√£o)
        st.subheader("üìä Nota Cr√≠tica (Insight)")
        st.warning(
            "**Descoberta Importante:** A an√°lise estat√≠stica revela que o **Sal√°rio M√©dio** "
            "e a **Experi√™ncia** s√£o fatores neutros (com m√©dia de ${:,.0f} e {:.1f} anos "
            "em todos os grupos). A alta acur√°cia do modelo (96%) √© integralmente baseada "
            "nas features categ√≥ricas (**Industry** e **Required Education**) ‚Äî ou seja, "
            "**onde voc√™ trabalha** e **o quanto voc√™ estudou**.\n\n"
            "Voc√™ pode confirmar isso na **Aba 2 (Feature Importance)**: o Median Salary e "
            "Experience Required devem estar nas √∫ltimas posi√ß√µes do gr√°fico, e as categorias "
            "como Industry: IT e Required Education: Bachelor's Degree devem estar no topo."
            .format(avg_low_salary, avg_low_experience)
        )
        
        st.markdown("---")
        
        # Insight Principal Corrigido (baseado na Feature Importance)
        st.subheader("üí° Padr√£o Corrigido, Baseado na Feature Importance")
        st.info(
            "**O modelo de 96% de acur√°cia ignora as m√©dias salariais** (que s√£o quase "
            "id√™nticas entre os grupos) **e foca nas categorias**. O verdadeiro padr√£o de "
            "risco √©:\n\n"
            "‚Ä¢ **O Maior Risco de Automa√ß√£o** √© atribu√≠do a profiss√µes em certas **Ind√∫strias** "
            "e que exigem apenas **High School**.\n\n"
            "‚Ä¢ **O Menor Risco de Automa√ß√£o** √© atribu√≠do a profiss√µes em outras **Ind√∫strias** "
            "e que exigem **Master's Degree ou PhD**.\n\n"
            "**Confirma√ß√£o:** Verifique o gr√°fico de Feature Importance na **Aba 2** para ver "
            "quais ind√∫strias e n√≠veis de educa√ß√£o o modelo considera mais importantes."
        )
        
        # Chamada para a√ß√£o (para LinkedIn)
        st.markdown("---")
        st.subheader("üß™ Teste Sua Intui√ß√£o!")
        st.warning(
            "**Desafio:** O modelo descobriu que **Ind√∫stria** e **N√≠vel de Educa√ß√£o** s√£o os "
            "fatores decisivos, n√£o o sal√°rio. Voc√™ consegue preencher os campos na barra "
            "lateral e provar que o modelo est√° errado? Use o **Previsor Interativo** para "
            "testar diferentes combina√ß√µes!"
        )
        
        # Estat√≠sticas adicionais (mant√©m para refer√™ncia)
        with st.expander("üìà Ver Estat√≠sticas Detalhadas (Refer√™ncia)"):
            col1, col2 = st.columns(2)
            with col1:
                st.write("**Baixo Risco (Low)**")
                st.write(f"- Total de amostras: {len(df_low):,}")
                st.write(f"- Sal√°rio m√©dio: ${avg_low_salary:,.0f}")
                st.write(f"- Experi√™ncia m√©dia: {avg_low_experience:.1f} anos")
                st.write(f"- Remoto m√©dio: {avg_low_remote:.1f}%")
            with col2:
                st.write("**Alto Risco (High)**")
                st.write(f"- Total de amostras: {len(df_high):,}")
                st.write(f"- Sal√°rio m√©dio: ${avg_high_salary:,.0f}")
                st.write(f"- Experi√™ncia m√©dia: {avg_high_experience:.1f} anos")
                st.write(f"- Remoto m√©dio: {avg_high_remote:.1f}%")

# --- 6. RODAP√â √âTICO ---
st.markdown("---")
st.caption("‚ö†Ô∏è **Aviso:** Este modelo √© uma ferramenta de an√°lise baseada em dados de 2024 e n√£o representa uma previs√£o definitiva do futuro. Os resultados devem ser interpretados como indicadores probabil√≠sticos e n√£o como garantias absolutas.")